{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Eminem Lyrics.ipynb","provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyOxwQDTpQVtN55XwSV1hv6M"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WeeaEkzGugLx","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxMdbsHGun2m","colab_type":"code","colab":{}},"source":["!pip install -q kaggle\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!ls ~/.kaggle\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOVauwE9U1FS","colab_type":"code","colab":{}},"source":["!kaggle datasets download -d paultimothymooney/poetry"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZIogLhIunM2","colab_type":"code","colab":{}},"source":["!unzip poetry.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtNfC9M9U-MF","colab_type":"code","colab":{}},"source":["!ls "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URKv0x9KkWTe","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gx4FFHVBVS0v","colab_type":"code","colab":{}},"source":["path_to_file = 'eminem.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0lRyS2WZWEm","colab_type":"code","colab":{}},"source":["text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"39rGzcHGjkbs","colab_type":"code","colab":{}},"source":["len(text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHVKaEYUjk2E","colab_type":"code","colab":{}},"source":["vocab = sorted(set(text))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"55gk-HsRj7nL","colab_type":"code","colab":{}},"source":["char2idx = {u:i for i,u in enumerate(vocab)}\n","index2char = np.array(vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcsHcr9bj8Iz","colab_type":"code","colab":{}},"source":["text_as_int = np.array([char2idx[c] for c in text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHpj1uD9khOq","colab_type":"code","colab":{}},"source":["text_as_int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phPepzPskk11","colab_type":"code","colab":{}},"source":["\"\".join(index2char[x] for x in text_as_int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rHtGnCUk0Ko","colab_type":"code","colab":{}},"source":["seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTp3qgiyl_id","colab_type":"code","colab":{}},"source":["for i in char_dataset.take(5):\n","  print(index2char[i.numpy()])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzHKN0xincO0","colab_type":"code","colab":{}},"source":["sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPpfsKeVok92","colab_type":"code","colab":{}},"source":["for item in sequences.take(5):\n","  print(repr(\"\".join(index2char[item.numpy()])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3H2a0XAYopN7","colab_type":"code","colab":{}},"source":["def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text = chunk[1:]\n","  return input_text, target_text\n","  \n","dataset = sequences.map(split_input_target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"558oJ5fIov9U","colab_type":"code","colab":{}},"source":["for inp, targ in dataset.take(2):\n","  print(inp.shape)\n","  print(targ.shape)\n","  # print(repr(\"\".join(index2char[inp.numpy()])))\n","  # print(repr(\"\".join(index2char[targ.numpy()])))\n","  print()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENuP6Ay-pl0-","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4_WzpcIqDlG","colab_type":"code","colab":{}},"source":["dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CAz4FHdqE4W","colab_type":"code","colab":{}},"source":["vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFiM86bcxQ0-","colab_type":"code","colab":{}},"source":["vocab_size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRQXQs0Ju8A9","colab_type":"code","colab":{}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","                               tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n","                               tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer=\"glorot_uniform\"),\n","                               tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9Iq73KrvqFJ","colab_type":"code","colab":{}},"source":["model = build_model(\n","    vocab_size = len(vocab),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units,\n","    batch_size=BATCH_SIZE\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqkxWTFUwbOq","colab_type":"code","colab":{}},"source":["for inp, tar in dataset.take(1):\n","  ex_pred = model(inp)\n","  print(ex_pred.shape, tar.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzQRr9shxNag","colab_type":"code","colab":{}},"source":["ex_pred[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vp8CyWT-xfSP","colab_type":"code","colab":{}},"source":["sample_indices = tf.random.categorical(ex_pred[0], num_samples=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJu4_oTByZCU","colab_type":"code","colab":{}},"source":["sample_indices = tf.squeeze(sample_indices, axis=-1).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9WOSBJ8yZ5A","colab_type":"code","colab":{}},"source":["sample_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zB2f__vyuk4","colab_type":"code","colab":{}},"source":["def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","ex_batch_loss = loss(tar, ex_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-I4Eo9RU0cqJ","colab_type":"code","colab":{}},"source":["ex_batch_loss.numpy().mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CD_zTsLT0e-A","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam', loss=loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVDRp7890pJ5","colab_type":"code","colab":{}},"source":["checkpoint_dir = './training_checkpoints'\n","\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKPea6GK1dxP","colab_type":"code","colab":{}},"source":["EPOCHS = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0I88bIrw11pX","colab_type":"code","colab":{}},"source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jxro8z3MIvmH","colab_type":"code","colab":{}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFwCkdALJBOD","colab_type":"code","colab":{}},"source":["model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCosjSPfJHWG","colab_type":"code","colab":{}},"source":["model.build(tf.TensorShape([1, None]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-amasUBR1-e2","colab_type":"code","colab":{}},"source":["start_string = \"Fucking\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgMjVQI9ITj0","colab_type":"code","colab":{}},"source":["input_eval = [char2idx[s] for s in start_string]\n","input_eval"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u75GHnBEIbJB","colab_type":"code","colab":{}},"source":["input_eval = tf.expand_dims(input_eval, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jj0QOV3IjVW","colab_type":"code","colab":{}},"source":["input_eval.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuXsy0t3Il18","colab_type":"code","colab":{}},"source":["prediction = model(input_eval)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUj5SpfkJUug","colab_type":"code","colab":{}},"source":["prediction.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"REMidZ_yIq9X","colab_type":"code","colab":{}},"source":["prediction.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LhWcGoTJUIr","colab_type":"code","colab":{}},"source":["prediction = tf.squeeze(prediction, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"alkIOCQhJh20","colab_type":"code","colab":{}},"source":["prediction.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMDKvLjrJi6p","colab_type":"code","colab":{}},"source":["prediction_id = tf.random.categorical(prediction, num_samples=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nK783MzSJqJr","colab_type":"code","colab":{}},"source":["prediction_id=prediction_id[-1, 0].numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXCNqrnmJraW","colab_type":"code","colab":{}},"source":["prediction_id"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vF0TNrh-J2Qj","colab_type":"code","colab":{}},"source":["tf.expand_dims([prediction_id], 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dlUzgS65KAbT","colab_type":"code","colab":{}},"source":["def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 1000\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 1.0\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the character returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted character as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      text_generated.append(index2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N53aFYHYK5Dd","colab_type":"code","colab":{}},"source":["print(generate_text(model, start_string=u\"Fucking\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"stYkKG_kK8ht","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}